{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Whsg1XX_OZs6"
      },
      "source": [
        "# Boilerplate\n",
        "\n",
        "Package installation, loading, and dataloaders. There's also a simple model defined. You can change it your favourite architecture if you want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "R1domTvnONqD",
        "outputId": "e6c42ae2-3f18-4b5d-cfe4-049c8d2983cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# !pip install tensorboardX\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "# from tensorboardX import SummaryWriter\n",
        "\n",
        "# use_cuda = False\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = torch.device('cpu')\n",
        "print(device)\n",
        "batch_size = 64\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "\n",
        "## Dataloaders\n",
        "train_dataset = datasets.MNIST('mnist_data/', train=True, download=True, transform=transforms.Compose(\n",
        "    [transforms.ToTensor()]\n",
        "))\n",
        "test_dataset = datasets.MNIST('mnist_data/', train=False, download=True, transform=transforms.Compose(\n",
        "    [transforms.ToTensor()]\n",
        "))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "\n",
        "## NN defined as specified in the assignment. 3 fully connected layers (followed by ReLU activations)\n",
        "## of size 50.\n",
        "## interval analysis function also defined here.\n",
        "class IntervalNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(IntervalNet, self).__init__()\n",
        "\n",
        "        # Define the network layers\n",
        "        self.fc1 = nn.Linear(28*28, 50)         # First fully connected layer\n",
        "        self.relu1 = nn.ReLU()                  # First ReLU\n",
        "        self.fc2 = nn.Linear(50, 50)            # Second fully connected layer\n",
        "        self.relu2 = nn.ReLU()                  # Second ReLU\n",
        "        self.fc3 = nn.Linear(50, 50)            # Third fully connected layer\n",
        "        self.relu3 = nn.ReLU()                  # Third ReLU\n",
        "        self.output_layer = nn.Linear(50, 10)   # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass through the layers\n",
        "        # flatten the images\n",
        "        x = x.view((-1, 28*28))\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.output_layer(x)  # No activation at the output layer\n",
        "        return x\n",
        "\n",
        "model = IntervalNet()\n",
        "\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Mja_AB4RykO"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "V-sw8yKYONqQ"
      },
      "outputs": [],
      "source": [
        "def train_model(model, num_epochs):\n",
        "    # TODO: implement this function that trains a given model on the MNIST dataset.\n",
        "    # this is a general-purpose function for both standard training and adversarial training.\n",
        "    # (toggle enable_defense parameter to switch between training schemes)\n",
        "    optimizer = optim.SGD(model.parameters())\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for _ in range(num_epochs):\n",
        "        # code adapted from official pytorch guide here: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
        "        # running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            # inputs, labels = data\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_func(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    print(\"Training complete\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "d1Ms3LAEMouJ"
      },
      "outputs": [],
      "source": [
        "def test_model(model):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for test_inputs, true_labels in test_loader:\n",
        "        test_inputs = test_inputs.to(device)\n",
        "        true_labels = true_labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(test_inputs)\n",
        "        test_loss += loss_func(output, true_labels).item()  # Sum up batch loss\n",
        "\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max log-probability\n",
        "\n",
        "        correct += pred.eq(true_labels.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "    print(f\"Test set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.2f}%)\")\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBUIl6vS-gIO",
        "outputId": "3b5666c4-6539-40a8-c3b7-f398a703ee12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training complete\n"
          ]
        }
      ],
      "source": [
        "train_model(model, 20)\n",
        "torch.save(model.state_dict(), 'weights.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA3VEZLtG39V"
      },
      "source": [
        "# Brief model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "b2ZPxo_QG8ve"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\haoli\\AppData\\Local\\Temp\\ipykernel_328\\1073835441.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('weights.pt'))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.0096, Accuracy: 8148/10000 (81.48%)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "81.48"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = IntervalNet().to(device)\n",
        "model.load_state_dict(torch.load('weights.pt'))\n",
        "\n",
        "test_model(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLrvM5Y1CPxK"
      },
      "source": [
        "# Evaluate on L-infinity neighborhoods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Define interval analysis functions\n",
        "def interval_propagation(model, x_min, x_max):\n",
        "    # Propagate through each layer of the model\n",
        "    for layer in model.children():\n",
        "        if isinstance(layer, nn.Linear):\n",
        "            x_min, x_max = propagate_linear(layer, x_min, x_max)\n",
        "        elif isinstance(layer, nn.ReLU):\n",
        "            x_min, x_max = propagate_relu(x_min, x_max)\n",
        "    return x_min, x_max\n",
        "\n",
        "def propagate_linear(layer, x_min, x_max):\n",
        "    W = layer.weight\n",
        "    b = layer.bias\n",
        "\n",
        "    # i think this is a fast way to do it instead of manually looping through the weights\n",
        "    W_positive = torch.clamp(W, min=0)  # positive part of W\n",
        "    W_negative = torch.clamp(W, max=0)  # negative part of W\n",
        "\n",
        "    # transpose for matrix multiplication. \n",
        "    x_min = torch.transpose(x_min, 0, 1)\n",
        "    x_max = torch.transpose(x_max, 0, 1)\n",
        "\n",
        "    # y_min without the bias\n",
        "    y_min = torch.transpose(torch.matmul(W_positive, x_min) + torch.matmul(W_negative, x_max), 0, 1) + b\n",
        "    y_max = torch.transpose(torch.matmul(W_positive, x_max) + torch.matmul(W_negative, x_min), 0, 1) + b\n",
        "\n",
        "    return y_min, y_max\n",
        "\n",
        "def propagate_relu(x_min, x_max):\n",
        "    # Apply ReLU interval-wise\n",
        "    return torch.relu(x_min), torch.relu(x_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "i-P1Q6iiCUIb"
      },
      "outputs": [],
      "source": [
        "# Define L-infinity neighborhood sizes (evenly spaced between 0.01 and 0.1)\n",
        "def evaluate_robustness(epss):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    for eps in epss:\n",
        "        robust = 0\n",
        "        total = 0\n",
        "\n",
        "        for samples, t_labels in test_loader:\n",
        "            samples = samples.to(device)\n",
        "            t_labels = t_labels.to(device)\n",
        "\n",
        "            samples = samples.view((-1, 28*28))  # Flatten MNIST image\n",
        "\n",
        "            # Define input intervals for L-infinity perturbation\n",
        "            x_min = samples - eps  # Lower bound of the interval\n",
        "            x_max = samples + eps  # Upper bound of the interval\n",
        "\n",
        "            # Perform interval propagation\n",
        "            output_min, output_max = interval_propagation(model, x_min, x_max)\n",
        "\n",
        "            # Evaluation in a neighborhood is robust, if the true label's minimum prediction\n",
        "            # is larger than any other label's maximum\n",
        "            for i in range(len(samples)):\n",
        "                total += 1\n",
        "                true_class_min = output_min[i][t_labels[i]]\n",
        "                output_max[i][t_labels[i]] = -1 # remove the true label's maximum from consideration\n",
        "                if output_max[i].max() < true_class_min:\n",
        "                    robust += 1\n",
        "\n",
        "        robustness = robust / total\n",
        "        print(f\"Robustness for epsilon {eps:.3f}: {robustness * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Robustness for epsilon 0.010: 0.00%\n",
            "Robustness for epsilon 0.020: 0.00%\n",
            "Robustness for epsilon 0.030: 0.00%\n",
            "Robustness for epsilon 0.040: 0.00%\n",
            "Robustness for epsilon 0.050: 0.00%\n",
            "Robustness for epsilon 0.060: 0.00%\n",
            "Robustness for epsilon 0.070: 0.00%\n",
            "Robustness for epsilon 0.080: 0.00%\n",
            "Robustness for epsilon 0.090: 0.00%\n",
            "Robustness for epsilon 0.100: 0.00%\n"
          ]
        }
      ],
      "source": [
        "epsilons = torch.linspace(0.01, 0.1, steps=10)\n",
        "\n",
        "evaluate_robustness(epsilons)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
