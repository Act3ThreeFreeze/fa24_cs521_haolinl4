{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Whsg1XX_OZs6"
      },
      "source": [
        "# Boilerplate\n",
        "\n",
        "Package installation, loading, and dataloaders. There's also a simple model defined. You can change it your favourite architecture if you want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "R1domTvnONqD",
        "outputId": "e6c42ae2-3f18-4b5d-cfe4-049c8d2983cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to mnist_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 35755840.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting mnist_data/MNIST/raw/train-images-idx3-ubyte.gz to mnist_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 1190370.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz to mnist_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 9566461.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz to mnist_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 7040106.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to mnist_data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# !pip install tensorboardX\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "# from tensorboardX import SummaryWriter\n",
        "\n",
        "# use_cuda = False\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# device = torch.device('cpu')\n",
        "print(device)\n",
        "batch_size = 64\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "\n",
        "## Dataloaders\n",
        "train_dataset = datasets.MNIST('mnist_data/', train=True, download=True, transform=transforms.Compose(\n",
        "    [transforms.ToTensor()]\n",
        "))\n",
        "test_dataset = datasets.MNIST('mnist_data/', train=False, download=True, transform=transforms.Compose(\n",
        "    [transforms.ToTensor()]\n",
        "))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "\n",
        "## NN defined as specified in the assignment. 3 fully connected layers (followed by ReLU activations)\n",
        "## of size 50.\n",
        "## interval analysis function also defined here.\n",
        "class IntervalNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(IntervalNet, self).__init__()\n",
        "\n",
        "        # Define the network layers\n",
        "        self.fc1 = nn.Linear(28*28, 50)  # First fully connected layer\n",
        "        self.relu1 = nn.ReLU()                # First ReLU\n",
        "        self.fc2 = nn.Linear(50, 50)          # Second fully connected layer\n",
        "        self.relu2 = nn.ReLU()                # Second ReLU\n",
        "        self.fc3 = nn.Linear(50, 50)          # Third fully connected layer\n",
        "        self.relu3 = nn.ReLU()                # Third ReLU\n",
        "        self.output_layer = nn.Linear(50, 10)  # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass through the layers\n",
        "        # flatten the images\n",
        "        x = x.view((-1, 28*28))\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.output_layer(x)  # No activation at the output layer\n",
        "        return x\n",
        "\n",
        "    def interval_propagation(self, x_min, x_max):\n",
        "        # Propagate through each layer of the model\n",
        "        for layer in self.model.children():\n",
        "            if isinstance(layer, nn.Linear):\n",
        "                x_min, x_max = self._propagate_linear(layer, x_min, x_max)\n",
        "            elif isinstance(layer, nn.ReLU):\n",
        "                x_min, x_max = self._propagate_relu(x_min, x_max)\n",
        "        return x_min, x_max\n",
        "\n",
        "    def _propagate_linear(self, layer, x_min, x_max):\n",
        "        W = layer.weight\n",
        "        b = layer.bias\n",
        "\n",
        "        # i think this is a fast way to do it instead of manually looping through the weights\n",
        "        W_positive = torch.clamp(W, min=0)  # positive part of W\n",
        "        W_negative = torch.clamp(W, max=0)  # negative part of W\n",
        "\n",
        "        # Interval bounds propagation through linear layers\n",
        "        y_min = W_positive @ x_min + W_negative @ x_max + b\n",
        "        y_max = W_positive @ x_max + W_negative @ x_min + b\n",
        "        return y_min, y_max\n",
        "\n",
        "    def _propagate_relu(self, x_min, x_max):\n",
        "        # Apply ReLU interval-wise\n",
        "        return torch.relu(x_min), torch.relu(x_max)\n",
        "\n",
        "class Normalize(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return (x - 0.1307)/0.3081\n",
        "\n",
        "# Add the data normalization as a first \"layer\" to the network\n",
        "# this allows us to search for adverserial examples to the real image, rather than\n",
        "# to the normalized image\n",
        "# model = nn.Sequential(Normalize(), Net())\n",
        "# image_size = 28 * 28\n",
        "# classes = 10\n",
        "model = IntervalNet()\n",
        "\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Mja_AB4RykO"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-sw8yKYONqQ"
      },
      "outputs": [],
      "source": [
        "def train_model(model, num_epochs):\n",
        "    # TODO: implement this function that trains a given model on the MNIST dataset.\n",
        "    # this is a general-purpose function for both standard training and adversarial training.\n",
        "    # (toggle enable_defense parameter to switch between training schemes)\n",
        "    optimizer = optim.SGD(model.parameters())\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # code adapted from official pytorch guide here: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
        "        # running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            # inputs, labels = data\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_func(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    print(\"Training complete\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1Ms3LAEMouJ"
      },
      "outputs": [],
      "source": [
        "def test_model(model):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for test_inputs, true_labels in test_loader:\n",
        "        test_inputs = test_inputs.to(device)\n",
        "        true_labels = true_labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(test_inputs)\n",
        "        test_loss += loss_func(output, true_labels).item()  # Sum up batch loss\n",
        "\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max log-probability\n",
        "\n",
        "        correct += pred.eq(true_labels.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "    print(f\"Test set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.2f}%)\")\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBUIl6vS-gIO",
        "outputId": "3b5666c4-6539-40a8-c3b7-f398a703ee12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training complete\n"
          ]
        }
      ],
      "source": [
        "train_model(model, 20)\n",
        "torch.save(model.state_dict(), 'weights.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA3VEZLtG39V"
      },
      "source": [
        "# Brief model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2ZPxo_QG8ve"
      },
      "outputs": [],
      "source": [
        "test_model(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLrvM5Y1CPxK"
      },
      "source": [
        "# Evaluate on L-infinity neighborhoods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-P1Q6iiCUIb"
      },
      "outputs": [],
      "source": [
        "# Define L-infinity neighborhood sizes (evenly spaced between 0.01 and 0.1)\n",
        "epsilon_values = torch.linspace(0.01, 0.1, steps=10)\n",
        "\n",
        "def evaluate_robustness(test_loader, epsilon_values):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    for epsilon in epsilon_values:\n",
        "        robust = 0\n",
        "        total = 0\n",
        "\n",
        "        for sample, t_label in test_loader:\n",
        "            sample = sample.to(device)\n",
        "            t_label = t_label.to(device)\n",
        "\n",
        "            sample = sample.view((-1, 28*28))  # Flatten MNIST image\n",
        "            total += 1\n",
        "\n",
        "            # Define input intervals for L-infinity perturbation\n",
        "            x_min = sample - epsilon  # Lower bound of the interval\n",
        "            x_max = sample + epsilon  # Upper bound of the interval\n",
        "\n",
        "            # Perform interval propagation\n",
        "            output_min, output_max = model.interval_propagation(x_min, x_max)\n",
        "\n",
        "            # Predicted label using the original (non-interval) input\n",
        "            pred_original = model(sample).argmax(dim=1)\n",
        "\n",
        "            # Check if the predicted class is consistent across the interval bounds\n",
        "            pred_min = output_min.argmax(dim=1)\n",
        "            pred_max = output_max.argmax(dim=1)\n",
        "\n",
        "            # Evaluation in a neighborhood is robust, if the true label's minimum prediction\n",
        "            # is larger than any other label's maximum\n",
        "            true_class_min = output_min[t_label]\n",
        "            output_max[t_label] = -1 # remove the true label's maximum from consideration\n",
        "            if output_max.max() < true_class_min:\n",
        "                robust += 1\n",
        "\n",
        "        robustness = robust / total\n",
        "        print(f\"Robustness for epsilon {epsilon:.3f}: {robustness * 100:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "0.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
